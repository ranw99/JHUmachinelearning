{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Full code with all data"
      ],
      "metadata": {
        "id": "V0XKsCZDKTD0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hszox7QhKQYb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.datasets import reuters\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load the Reuters dataset\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(\n",
        "    path=\"reuters.npz\",\n",
        "    num_words=None,\n",
        "    skip_top=0,\n",
        "    maxlen=None,\n",
        "    test_split=0.2,\n",
        "    seed=113,\n",
        "    start_char=1,\n",
        "    oov_char=2,\n",
        "    index_from=3\n",
        ")\n",
        "\n",
        "# Retrieve the word index file mapping words to indices\n",
        "word_index = reuters.get_word_index()\n",
        "\n",
        "# Reverse word index to decode reviews back to text\n",
        "index_to_word = {value + 3: key for key, value in word_index.items()}\n",
        "index_to_word[0] = '<pad>'\n",
        "index_to_word[1] = '<sos>'\n",
        "index_to_word[2] = '<oov>'\n",
        "\n",
        "# Decode the train and test data\n",
        "train_texts = [' '.join(index_to_word.get(i, '?') for i in train_sequence) for train_sequence in train_data]\n",
        "test_texts = [' '.join(index_to_word.get(i, '?') for i in test_sequence) for test_sequence in test_data]\n",
        "\n",
        "# Define positive and negative words for financial texts (expand this list based on your needs)\n",
        "positive_words = ['profitable', 'gains', 'growth', 'bullish', 'upswing', 'rally', 'exceed']\n",
        "negative_words = ['losses', 'decline', 'bearish', 'downturn', 'fall', 'dropped', 'slump']\n",
        "\n",
        "# Function to determine sentiment\n",
        "def determine_sentiment(text):\n",
        "    text = text.lower()\n",
        "    if any(word in text for word in positive_words):\n",
        "        return 'positive'\n",
        "    elif any(word in text for word in negative_words):\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "# Convert train and test data into DataFrame\n",
        "train_df = pd.DataFrame({'text': train_texts, 'label': train_labels})\n",
        "test_df = pd.DataFrame({'text': test_texts, 'label': test_labels})\n",
        "\n",
        "# Apply sentiment determination\n",
        "train_df['sentiment'] = train_df['text'].apply(determine_sentiment)\n",
        "test_df['sentiment'] = test_df['text'].apply(determine_sentiment)\n",
        "\n",
        "# Use TfidfVectorizer and Logistic Regression\n",
        "tfidf = TfidfVectorizer(strip_accents=None, lowercase=False, preprocessor=None)\n",
        "param_grid = {\n",
        "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
        "    'vect__stop_words': [None],\n",
        "    'vect__tokenizer': [None],\n",
        "    'clf__penalty': ['l1', 'l2'],\n",
        "    'clf__C': [1.0, 10.0, 100.0]\n",
        "}\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('vect', tfidf),\n",
        "    ('clf', LogisticRegression(random_state=0, solver='liblinear'))\n",
        "])\n",
        "\n",
        "gs = GridSearchCV(pipeline, param_grid, scoring='accuracy', cv=5, verbose=2, n_jobs=-1)\n",
        "gs.fit(train_df['text'], train_df['sentiment'])\n",
        "\n",
        "# Output best score and parameters\n",
        "print(\"Best score: \", gs.best_score_)\n",
        "print(\"Best parameters: \", gs.best_params_)\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_score = gs.score(test_df['text'], test_df['sentiment'])\n",
        "print(\"Test accuracy: \", test_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using 10% of data"
      ],
      "metadata": {
        "id": "BLhAsCgrKYwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from keras.datasets import reuters\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Load the Reuters dataset\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(\n",
        "    path=\"reuters.npz\",\n",
        "    num_words=None,\n",
        "    skip_top=0,\n",
        "    maxlen=None,\n",
        "    test_split=0.2,\n",
        "    seed=113,\n",
        "    start_char=1,\n",
        "    oov_char=2,\n",
        "    index_from=3\n",
        ")\n",
        "\n",
        "# Retrieve the word index file mapping words to indices\n",
        "word_index = reuters.get_word_index()\n",
        "\n",
        "# Reverse word index to decode reviews back to text\n",
        "index_to_word = {value + 3: key for key, value in word_index.items()}\n",
        "index_to_word[0] = '<pad>'\n",
        "index_to_word[1] = '<sos>'\n",
        "index_to_word[2] = '<oov>'\n",
        "\n",
        "# Decode the train and test data\n",
        "train_texts = [' '.join(index_to_word.get(i, '?') for i in train_sequence) for train_sequence in train_data]\n",
        "test_texts = [' '.join(index_to_word.get(i, '?') for i in test_sequence) for test_sequence in test_data]\n",
        "\n",
        "# Define positive and negative words for financial texts\n",
        "positive_words = [\n",
        "    'profitable', 'gains', 'growth', 'bullish', 'upswing', 'rally', 'exceed',\n",
        "    'outperform', 'robust', 'success', 'advantageous', 'beneficial', 'boom',\n",
        "    'thrive', 'prosperous', 'dividend'\n",
        "]\n",
        "\n",
        "negative_words = [\n",
        "    'losses', 'decline', 'bearish', 'downturn', 'fall', 'dropped', 'slump',\n",
        "    'worsened', 'risky', 'problem', 'deficit', 'debt', 'crisis', 'collapse',\n",
        "    'detrimental', 'fail'\n",
        "]\n",
        "\n",
        "# Function to determine sentiment\n",
        "def determine_sentiment(text):\n",
        "    text = text.lower()\n",
        "    if any(word in text for word in positive_words):\n",
        "        return 'positive'\n",
        "    elif any(word in text for word in negative_words):\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "# Convert train and test data into DataFrame\n",
        "train_df = pd.DataFrame({'text': train_texts})\n",
        "test_df = pd.DataFrame({'text': test_texts})\n",
        "\n",
        "# Apply sentiment determination\n",
        "train_df['sentiment'] = train_df['text'].apply(determine_sentiment)\n",
        "test_df['sentiment'] = test_df['text'].apply(determine_sentiment)\n",
        "\n",
        "# Sample data for faster execution\n",
        "train_df_sample = train_df.sample(frac=0.1, random_state=42)\n",
        "test_df_sample = test_df.sample(frac=0.1, random_state=42)\n",
        "\n",
        "# Simplified parameter grid\n",
        "param_grid = {\n",
        "    'vect__ngram_range': [(1, 1)],\n",
        "    'vect__stop_words': [None],\n",
        "    'clf__penalty': ['l2'],\n",
        "    'clf__C': [1.0, 10.0]\n",
        "}\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('vect', TfidfVectorizer(strip_accents=None, lowercase=False, preprocessor=None)),\n",
        "    ('clf', LogisticRegression(random_state=0, solver='saga', max_iter=100))\n",
        "])\n",
        "\n",
        "gs = GridSearchCV(pipeline, param_grid, scoring='accuracy', cv=3, verbose=2, n_jobs=-1)\n",
        "gs.fit(train_df_sample['text'], train_df_sample['sentiment'])\n",
        "\n",
        "# Output best score and parameters\n",
        "print(\"Best score: \", gs.best_score_)\n",
        "print(\"Best parameters: \", gs.best_params_)\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_score = gs.score(test_df_sample['text'], test_df_sample['sentiment'])\n",
        "print(\"Test accuracy: \", test_score)\n"
      ],
      "metadata": {
        "id": "i59eissmKarp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}